{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 5. 안전 운전자 예측 경진대회 성능 개선 II : XGBoost 모델\n\n- 이번에는 모델만 XGBoost로 바꾸겠다\n- XGBoost란 성능이 우수한 트리 기반 부스팅 알고리즘\n- 결정 트리를 병렬로 배치하는 랜덤 포레스트와 달리 직렬로 배치해 사용\n\n\n- 앞 절에서 사용한 코드를 XGBoost 기반으로 바꾸려면 몇 가지를 수정해야 함\n    1. 지니계수 변환값\n    2. 데이터셋 객체\n    3. 모델 하이퍼파라미터명","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\n\ntrain = pd.read_csv(data_path + 'train.csv', index_col='id')\ntest = pd.read_csv(data_path + 'test.csv', index_col='id')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-03T11:19:07.821194Z","iopub.execute_input":"2023-04-03T11:19:07.821985Z","iopub.status.idle":"2023-04-03T11:19:19.522279Z","shell.execute_reply.started":"2023-04-03T11:19:07.821937Z","shell.execute_reply":"2023-04-03T11:19:19.521033Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## 5-1. 피처 엔지니어링\n\n### 5-1-1. 정규화 지니계수 계산 함수\n\n- Note that: LightGBM용 gini() 함수\n\n```python\n# LightGBM용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds), True # 반환값\n```\n\n- 평가점수가 높으면 좋은지 여부는 XGBoost 모델 객체의 train() 메서드에 따로 전달해야 함","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n    assert y_true.shape == y_pred.shape\n\n    n_samples = y_true.shape[0]                      # 데이터 개수\n    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n\n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n\n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n    G_true = np.sum(L_mid - L_true)       # 예측이 완벽할 때 지니계수\n\n    # 정규화된 지니계수\n    return G_pred / G_true","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:28:31.463361Z","iopub.execute_input":"2023-04-03T11:28:31.464563Z","iopub.status.idle":"2023-04-03T11:28:31.473155Z","shell.execute_reply.started":"2023-04-03T11:28:31.464515Z","shell.execute_reply":"2023-04-03T11:28:31.471683Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# XGBoost용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:28:33.596451Z","iopub.execute_input":"2023-04-03T11:28:33.596914Z","iopub.status.idle":"2023-04-03T11:28:33.602319Z","shell.execute_reply.started":"2023-04-03T11:28:33.596874Z","shell.execute_reply":"2023-04-03T11:28:33.601372Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### 5-1-2. 데이터 합치기","metadata":{}},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop('target', axis=1) # 타깃값 제거\n\nall_features = all_data.columns # 전체 피처","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:29:07.976184Z","iopub.execute_input":"2023-04-03T11:29:07.977158Z","iopub.status.idle":"2023-04-03T11:29:09.372160Z","shell.execute_reply.started":"2023-04-03T11:29:07.977115Z","shell.execute_reply":"2023-04-03T11:29:09.371069Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### 5-1-3. 명목형 피처 원-핫 인코딩","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# 명목형 피처\ncat_features = [feature for feature in all_features if 'cat' in feature]\n\n# 원-핫 인코딩 적용\nonehot_encoder = OneHotEncoder()\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:29:23.268982Z","iopub.execute_input":"2023-04-03T11:29:23.269401Z","iopub.status.idle":"2023-04-03T11:29:25.713862Z","shell.execute_reply.started":"2023-04-03T11:29:23.269364Z","shell.execute_reply":"2023-04-03T11:29:25.712587Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### 5-1-4. 파생 피처 추가","metadata":{}},{"cell_type":"code","source":"# '데이터 하나당 결측값 개수'를 파생 피처로 추가\nall_data['num_missing'] = (all_data==-1).sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:01.903940Z","iopub.execute_input":"2023-04-03T11:30:01.904399Z","iopub.status.idle":"2023-04-03T11:30:02.114858Z","shell.execute_reply.started":"2023-04-03T11:30:01.904358Z","shell.execute_reply":"2023-04-03T11:30:02.113346Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# 명목형 피처, calc 분류 피처를 제외한 피처\nremaining_features = [feature for feature in all_features\n                      if ('cat' not in feature and 'calc' not in feature)] \n# num_missing을 remaining_features에 추가\nremaining_features.append('num_missing')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:02.117019Z","iopub.execute_input":"2023-04-03T11:30:02.117425Z","iopub.status.idle":"2023-04-03T11:30:02.125526Z","shell.execute_reply.started":"2023-04-03T11:30:02.117387Z","shell.execute_reply":"2023-04-03T11:30:02.124109Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 분류가 ind인 피처\nind_features = [feature for feature in all_features if 'ind' in feature]\n\nis_first_feature = True\nfor ind_feature in ind_features:\n    if is_first_feature:\n        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n        is_first_feature = False\n    else:\n        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '_'","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:02.202018Z","iopub.execute_input":"2023-04-03T11:30:02.202458Z","iopub.status.idle":"2023-04-03T11:30:25.095685Z","shell.execute_reply.started":"2023-04-03T11:30:02.202419Z","shell.execute_reply":"2023-04-03T11:30:25.094412Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"all_data['mix_ind']","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:25.097947Z","iopub.execute_input":"2023-04-03T11:30:25.098411Z","iopub.status.idle":"2023-04-03T11:30:25.109232Z","shell.execute_reply.started":"2023-04-03T11:30:25.098365Z","shell.execute_reply":"2023-04-03T11:30:25.107977Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0          2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_\n1           1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_\n2          5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_\n3           0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_\n4           0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_\n                           ...                  \n1488023     0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_\n1488024    5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_\n1488025     0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_\n1488026    6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_\n1488027    7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_\nName: mix_ind, Length: 1488028, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"cat_count_features = []\nfor feature in cat_features+['mix_ind']:\n    val_counts_dict = all_data[feature].value_counts().to_dict()\n    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: \n                                                           val_counts_dict[x])\n    cat_count_features.append(f'{feature}_count')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:25.110999Z","iopub.execute_input":"2023-04-03T11:30:25.111768Z","iopub.status.idle":"2023-04-03T11:30:35.346990Z","shell.execute_reply.started":"2023-04-03T11:30:25.111703Z","shell.execute_reply":"2023-04-03T11:30:35.345847Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"cat_count_features","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:35.349167Z","iopub.execute_input":"2023-04-03T11:30:35.349514Z","iopub.status.idle":"2023-04-03T11:30:35.356312Z","shell.execute_reply.started":"2023-04-03T11:30:35.349482Z","shell.execute_reply":"2023-04-03T11:30:35.355192Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['ps_ind_02_cat_count',\n 'ps_ind_04_cat_count',\n 'ps_ind_05_cat_count',\n 'ps_car_01_cat_count',\n 'ps_car_02_cat_count',\n 'ps_car_03_cat_count',\n 'ps_car_04_cat_count',\n 'ps_car_05_cat_count',\n 'ps_car_06_cat_count',\n 'ps_car_07_cat_count',\n 'ps_car_08_cat_count',\n 'ps_car_09_cat_count',\n 'ps_car_10_cat_count',\n 'ps_car_11_cat_count',\n 'mix_ind_count']"},"metadata":{}}]},{"cell_type":"markdown","source":"### 5-1-5. 필요 없는 피처 제거","metadata":{}},{"cell_type":"code","source":"from scipy import sparse\n\n# 필요 없는 피처들\ndrop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', \n                 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n\n# remaining_features, cat_count_features에서 drop_features를 제거한 데이터\nall_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n\n# 데이터 합치기\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n                               encoded_cat_matrix],\n                              format='csr')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:35.357684Z","iopub.execute_input":"2023-04-03T11:30:35.358061Z","iopub.status.idle":"2023-04-03T11:30:41.509133Z","shell.execute_reply.started":"2023-04-03T11:30:35.358026Z","shell.execute_reply":"2023-04-03T11:30:41.508080Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### 5-1-6. 데이터 나누기","metadata":{}},{"cell_type":"code","source":"num_train = len(train) # 훈련 데이터 개수\n\n# 훈련 데이터와 테스트 데이터 나누기\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\n\ny = train['target'].values","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:30:41.510260Z","iopub.execute_input":"2023-04-03T11:30:41.510565Z","iopub.status.idle":"2023-04-03T11:30:42.726976Z","shell.execute_reply.started":"2023-04-03T11:30:41.510537Z","shell.execute_reply":"2023-04-03T11:30:42.725961Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 5-2. 하이퍼파라미터 최적화","metadata":{}},{"cell_type":"markdown","source":"\n\n- LightGBM 모델링 때와 마찬가지로 베이지안 최적화를 수행\n\n### 5-2-1. 데이터셋 준비\n\n- \"LightGBM\"은 `lgb.Dataset()`으로 데이터셋을 만든다\n- \"XGBoost\"는 `xgb.DMatrix()`으로 만든다","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\n# 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size=0.2, \n                                                      random_state=0)\n# 베이지안 최적화용 데이터셋\nbayes_dtrain = xgb.DMatrix(X_train, y_train)\nbayes_dvalid = xgb.DMatrix(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:32:14.182970Z","iopub.execute_input":"2023-04-03T11:32:14.183415Z","iopub.status.idle":"2023-04-03T11:32:14.932969Z","shell.execute_reply.started":"2023-04-03T11:32:14.183380Z","shell.execute_reply":"2023-04-03T11:32:14.931942Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 5-2-2. 하이퍼파라미터 범위 설정","metadata":{}},{"cell_type":"code","source":"# 베이지안 최적화를 위한 하이퍼파라미터 범위\nparam_bounds = {'max_depth': (4, 8),\n                'subsample': (0.6, 0.9),\n                'colsample_bytree': (0.7, 1.0),\n                'min_child_weight': (5, 7),\n                'gamma': (8, 11),\n                'reg_alpha': (7, 9),\n                'reg_lambda': (1.1, 1.5),\n                'scale_pos_weight': (1.4, 1.6)}\n\n# 값이 고정된 하이퍼파라미터\nfixed_params = {'objective': 'binary:logistic',\n                'learning_rate': 0.02,\n                'random_state': 1991}","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:33:49.593967Z","iopub.execute_input":"2023-04-03T11:33:49.594347Z","iopub.status.idle":"2023-04-03T11:33:49.601625Z","shell.execute_reply.started":"2023-04-03T11:33:49.594314Z","shell.execute_reply":"2023-04-03T11:33:49.600334Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### 5-2-3. (베이지안 최적화용) 평가지표 계산 함수 작성\n\n- 베이지안 최적화에 사용하기 위한 `eval_function()` 함수를 살펴보자\n- 이 함수는 XGBoost 하이퍼파라미터를 인수로 받아서 XGBoost를 훈련한 뒤 평가지표인 지니계수를 반환\n- 큰 흐름은 LigthGBM용 `eval_function()`과 유사하며 다른점은 다음과 같다.\n    - 하이퍼파라미터 이름\n    - `train()` 메서드 내 검증 데이터 전달 방식\n    - `train()` 메서드 내 maximize 파라미터\n    - `prediction()` 메서드에 `DMatrix` 타입을 전달하는 점","metadata":{}},{"cell_type":"code","source":"def eval_function(max_depth, subsample, colsample_bytree, min_child_weight,\n                 reg_alpha, gamma, reg_lambda, scale_pos_weight):\n    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n    # 베이지안 최적화를 수행할 하이퍼파라미터\n    params = {'max_depth': int(round(max_depth)),\n              'subsample': subsample,\n              'colsample_bytree': colsample_bytree,\n              'min_child_weight': min_child_weight,\n              'gamma': gamma,\n              'reg_alpha':reg_alpha,\n              'reg_lambda': reg_lambda,\n              'scale_pos_weight': scale_pos_weight}\n    # 값이 고정된 하이퍼파라미터도 추가\n    params.update(fixed_params)\n    \n    print('하이퍼파라미터 :', params)    \n        \n    # XGBoost 모델 훈련\n    xgb_model = xgb.train(params=params, \n                          dtrain=bayes_dtrain,\n                          num_boost_round=2000,\n                          evals=[(bayes_dvalid, 'bayes_dvalid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=False)\n                           \n    best_iter = xgb_model.best_iteration # 최적 반복 횟수\n    # 검증 데이터로 예측 수행\n    preds = xgb_model.predict(bayes_dvalid, \n                              iteration_range=(0, best_iter))\n    # 지니계수 계산\n    gini_score = eval_gini(y_valid, preds)\n    print(f'지니계수 : {gini_score}\\n')\n    \n    return gini_score","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:36:48.514921Z","iopub.execute_input":"2023-04-03T11:36:48.515344Z","iopub.status.idle":"2023-04-03T11:36:48.525631Z","shell.execute_reply.started":"2023-04-03T11:36:48.515309Z","shell.execute_reply":"2023-04-03T11:36:48.524507Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### 5-2-4. 최적화 수행","metadata":{}},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\n# 베이지안 최적화 객체 생성\noptimizer = BayesianOptimization(f=eval_function, \n                                 pbounds=param_bounds, \n                                 random_state=0)\n\n# 베이지안 최적화 수행\noptimizer.maximize(init_points=3, n_iter=6)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T11:41:53.833445Z","iopub.execute_input":"2023-04-03T11:41:53.833923Z","iopub.status.idle":"2023-04-03T14:20:20.459200Z","shell.execute_reply.started":"2023-04-03T11:41:53.833879Z","shell.execute_reply":"2023-04-03T14:20:20.457846Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | scale_... | subsample |\n-------------------------------------------------------------------------------------------------------------------------\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.867531900234624, 'colsample_bytree': 0.8646440511781974, 'min_child_weight': 6.0897663659937935, 'gamma': 10.14556809911726, 'reg_alpha': 7.84730959867781, 'reg_lambda': 1.3583576452266626, 'scale_pos_weight': 1.4875174422525386, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28470429444834217\n\n| \u001b[0m1        \u001b[0m | \u001b[0m0.2847   \u001b[0m | \u001b[0m0.8646   \u001b[0m | \u001b[0m10.15    \u001b[0m | \u001b[0m6.411    \u001b[0m | \u001b[0m6.09     \u001b[0m | \u001b[0m7.847    \u001b[0m | \u001b[0m1.358    \u001b[0m | \u001b[0m1.488    \u001b[0m | \u001b[0m0.8675   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6261387899104622, 'colsample_bytree': 0.9890988281503088, 'min_child_weight': 6.0577898395058085, 'gamma': 9.150324556477333, 'reg_alpha': 8.136089122187865, 'reg_lambda': 1.4702386553170643, 'scale_pos_weight': 1.4142072116395774, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n지니계수 : 0.2851953200460391\n\n| \u001b[95m2        \u001b[0m | \u001b[95m0.2852   \u001b[0m | \u001b[95m0.9891   \u001b[0m | \u001b[95m9.15     \u001b[0m | \u001b[95m7.167    \u001b[0m | \u001b[95m6.058    \u001b[0m | \u001b[95m8.136    \u001b[0m | \u001b[95m1.47     \u001b[0m | \u001b[95m1.414    \u001b[0m | \u001b[95m0.6261   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.8341587528859367, 'colsample_bytree': 0.7060655192320977, 'min_child_weight': 6.7400242964936385, 'gamma': 10.497859536643814, 'reg_alpha': 8.957236684465528, 'reg_lambda': 1.4196634256866894, 'scale_pos_weight': 1.4922958724505864, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n지니계수 : 0.28359402092703206\n\n| \u001b[0m3        \u001b[0m | \u001b[0m0.2836   \u001b[0m | \u001b[0m0.7061   \u001b[0m | \u001b[0m10.5     \u001b[0m | \u001b[0m7.113    \u001b[0m | \u001b[0m6.74     \u001b[0m | \u001b[0m8.957    \u001b[0m | \u001b[0m1.42     \u001b[0m | \u001b[0m1.492    \u001b[0m | \u001b[0m0.8342   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.7057465489757903, 'colsample_bytree': 0.9998951077352971, 'min_child_weight': 6.187240983605598, 'gamma': 9.270868061681206, 'reg_alpha': 8.219782862530412, 'reg_lambda': 1.177504564476268, 'scale_pos_weight': 1.509981196211439, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2844278865791322\n\n| \u001b[0m4        \u001b[0m | \u001b[0m0.2844   \u001b[0m | \u001b[0m0.9999   \u001b[0m | \u001b[0m9.271    \u001b[0m | \u001b[0m6.987    \u001b[0m | \u001b[0m6.187    \u001b[0m | \u001b[0m8.22     \u001b[0m | \u001b[0m1.178    \u001b[0m | \u001b[0m1.51     \u001b[0m | \u001b[0m0.7057   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.8535233675350644, 'colsample_bytree': 0.92975858050776, 'min_child_weight': 6.249564429359247, 'gamma': 9.95563546750357, 'reg_alpha': 8.411512219837842, 'reg_lambda': 1.424460008293778, 'scale_pos_weight': 1.5416807226581535, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2856515869205076\n\n| \u001b[95m5        \u001b[0m | \u001b[95m0.2857   \u001b[0m | \u001b[95m0.9298   \u001b[0m | \u001b[95m9.956    \u001b[0m | \u001b[95m6.809    \u001b[0m | \u001b[95m6.25     \u001b[0m | \u001b[95m8.412    \u001b[0m | \u001b[95m1.424    \u001b[0m | \u001b[95m1.542    \u001b[0m | \u001b[95m0.8535   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6462619019069298, 'colsample_bytree': 0.80929192865947, 'min_child_weight': 6.079999276892042, 'gamma': 9.553916776586505, 'reg_alpha': 8.860396362258099, 'reg_lambda': 1.4050740023119348, 'scale_pos_weight': 1.4668544695338273, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28466544765284935\n\n| \u001b[0m6        \u001b[0m | \u001b[0m0.2847   \u001b[0m | \u001b[0m0.8093   \u001b[0m | \u001b[0m9.554    \u001b[0m | \u001b[0m6.532    \u001b[0m | \u001b[0m6.08     \u001b[0m | \u001b[0m8.86     \u001b[0m | \u001b[0m1.405    \u001b[0m | \u001b[0m1.467    \u001b[0m | \u001b[0m0.6463   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6931141936797243, 'colsample_bytree': 0.8817801730078565, 'min_child_weight': 6.992334203641873, 'gamma': 9.013424730095146, 'reg_alpha': 7.640858389939128, 'reg_lambda': 1.3562805915715632, 'scale_pos_weight': 1.449446257931491, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28550424648809736\n\n| \u001b[0m7        \u001b[0m | \u001b[0m0.2855   \u001b[0m | \u001b[0m0.8818   \u001b[0m | \u001b[0m9.013    \u001b[0m | \u001b[0m6.927    \u001b[0m | \u001b[0m6.992    \u001b[0m | \u001b[0m7.641    \u001b[0m | \u001b[0m1.356    \u001b[0m | \u001b[0m1.449    \u001b[0m | \u001b[0m0.6931   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 5, 'subsample': 0.6261564417044092, 'colsample_bytree': 0.8763145220620449, 'min_child_weight': 5.135323353557588, 'gamma': 8.39495450163982, 'reg_alpha': 8.950443047087845, 'reg_lambda': 1.4235649099168255, 'scale_pos_weight': 1.5217625173811569, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2840512946560939\n\n| \u001b[0m8        \u001b[0m | \u001b[0m0.2841   \u001b[0m | \u001b[0m0.8763   \u001b[0m | \u001b[0m8.395    \u001b[0m | \u001b[0m4.561    \u001b[0m | \u001b[0m5.135    \u001b[0m | \u001b[0m8.95     \u001b[0m | \u001b[0m1.424    \u001b[0m | \u001b[0m1.522    \u001b[0m | \u001b[0m0.6262   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.857971740304964, 'colsample_bytree': 0.9583821245229369, 'min_child_weight': 6.158305055403563, 'gamma': 9.305332775334449, 'reg_alpha': 8.200928434091152, 'reg_lambda': 1.2571039588093065, 'scale_pos_weight': 1.4700266933495618, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2845833465457728\n\n| \u001b[0m9        \u001b[0m | \u001b[0m0.2846   \u001b[0m | \u001b[0m0.9584   \u001b[0m | \u001b[0m9.305    \u001b[0m | \u001b[0m5.594    \u001b[0m | \u001b[0m6.158    \u001b[0m | \u001b[0m8.201    \u001b[0m | \u001b[0m1.257    \u001b[0m | \u001b[0m1.47     \u001b[0m | \u001b[0m0.858    \u001b[0m |\n=========================================================================================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 5-2-5. 결과 확인","metadata":{}},{"cell_type":"code","source":"# 평가함수 점수가 최대일 때 하이퍼파라미터\nmax_params = optimizer.max['params']\nmax_params","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:20:20.461456Z","iopub.execute_input":"2023-04-03T14:20:20.461969Z","iopub.status.idle":"2023-04-03T14:20:20.470904Z","shell.execute_reply.started":"2023-04-03T14:20:20.461917Z","shell.execute_reply":"2023-04-03T14:20:20.469613Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'colsample_bytree': 0.92975858050776,\n 'gamma': 9.95563546750357,\n 'max_depth': 6.809274695878221,\n 'min_child_weight': 6.249564429359247,\n 'reg_alpha': 8.411512219837842,\n 'reg_lambda': 1.424460008293778,\n 'scale_pos_weight': 1.5416807226581535,\n 'subsample': 0.8535233675350644}"},"metadata":{}}]},{"cell_type":"code","source":"# 정수형 하이퍼파라미터 변환\nmax_params['max_depth'] = int(round(max_params['max_depth']))\n\n# 값이 고정된 하이퍼파라미터 추가\nmax_params.update(fixed_params)\nmax_params","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:20:20.472422Z","iopub.execute_input":"2023-04-03T14:20:20.472896Z","iopub.status.idle":"2023-04-03T14:20:20.488189Z","shell.execute_reply.started":"2023-04-03T14:20:20.472844Z","shell.execute_reply":"2023-04-03T14:20:20.486773Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'colsample_bytree': 0.92975858050776,\n 'gamma': 9.95563546750357,\n 'max_depth': 7,\n 'min_child_weight': 6.249564429359247,\n 'reg_alpha': 8.411512219837842,\n 'reg_lambda': 1.424460008293778,\n 'scale_pos_weight': 1.5416807226581535,\n 'subsample': 0.8535233675350644,\n 'objective': 'binary:logistic',\n 'learning_rate': 0.02,\n 'random_state': 1991}"},"metadata":{}}]},{"cell_type":"markdown","source":"## 5-3. 모델 훈련 및 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\n# 층화 K 폴드 교차 검증기 생성\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n\n# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0]) \n# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0]) \n\n# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    # 각 폴드를 구분하는 문구 출력\n    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n    \n    # 훈련용 데이터, 검증용 데이터 설정\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n\n    # XGBoost 전용 데이터셋 생성 \n    dtrain = xgb.DMatrix(X_train, y_train)\n    dvalid = xgb.DMatrix(X_valid, y_valid)\n    dtest = xgb.DMatrix(X_test)\n    # XGBoost 모델 훈련\n    xgb_model = xgb.train(params=max_params, \n                          dtrain=dtrain,\n                          num_boost_round=2000,\n                          evals=[(dvalid, 'valid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=100)\n\n    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n    best_iter = xgb_model.best_iteration\n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += xgb_model.predict(dtest,\n                                        iteration_range=(0, best_iter))/folds.n_splits\n    \n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n    oof_val_preds[valid_idx] += xgb_model.predict(dvalid, \n                                                  iteration_range=(0, best_iter))\n    \n    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:20:20.491431Z","iopub.execute_input":"2023-04-03T14:20:20.492053Z","iopub.status.idle":"2023-04-03T15:51:32.232117Z","shell.execute_reply.started":"2023-04-03T14:20:20.492003Z","shell.execute_reply":"2023-04-03T15:51:32.230818Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"######################################## 폴드 1 / 폴드 5 ########################################\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalid-logloss:0.67679\tvalid-gini:0.17960\n[100]\tvalid-logloss:0.19334\tvalid-gini:0.25125\n[200]\tvalid-logloss:0.15933\tvalid-gini:0.28002\n[300]\tvalid-logloss:0.15588\tvalid-gini:0.28885\n[400]\tvalid-logloss:0.15532\tvalid-gini:0.29364\n[500]\tvalid-logloss:0.15517\tvalid-gini:0.29628\n[600]\tvalid-logloss:0.15512\tvalid-gini:0.29734\n[700]\tvalid-logloss:0.15506\tvalid-gini:0.29835\n[800]\tvalid-logloss:0.15504\tvalid-gini:0.29889\n[900]\tvalid-logloss:0.15502\tvalid-gini:0.29929\n[1000]\tvalid-logloss:0.15502\tvalid-gini:0.29941\n[1100]\tvalid-logloss:0.15501\tvalid-gini:0.29926\n[1200]\tvalid-logloss:0.15502\tvalid-gini:0.29893\n[1237]\tvalid-logloss:0.15501\tvalid-gini:0.29918\n폴드 1 지니계수 : 0.29944651710485193\n\n######################################## 폴드 2 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67679\tvalid-gini:0.15338\n[100]\tvalid-logloss:0.19344\tvalid-gini:0.24163\n[200]\tvalid-logloss:0.15961\tvalid-gini:0.26533\n[300]\tvalid-logloss:0.15623\tvalid-gini:0.27503\n[400]\tvalid-logloss:0.15572\tvalid-gini:0.27898\n[500]\tvalid-logloss:0.15557\tvalid-gini:0.28163\n[600]\tvalid-logloss:0.15551\tvalid-gini:0.28304\n[700]\tvalid-logloss:0.15549\tvalid-gini:0.28402\n[800]\tvalid-logloss:0.15548\tvalid-gini:0.28434\n[900]\tvalid-logloss:0.15546\tvalid-gini:0.28446\n[1000]\tvalid-logloss:0.15545\tvalid-gini:0.28503\n[1100]\tvalid-logloss:0.15544\tvalid-gini:0.28541\n[1200]\tvalid-logloss:0.15543\tvalid-gini:0.28571\n[1300]\tvalid-logloss:0.15543\tvalid-gini:0.28575\n[1400]\tvalid-logloss:0.15543\tvalid-gini:0.28578\n[1500]\tvalid-logloss:0.15543\tvalid-gini:0.28575\n[1600]\tvalid-logloss:0.15544\tvalid-gini:0.28572\n[1670]\tvalid-logloss:0.15544\tvalid-gini:0.28555\n폴드 2 지니계수 : 0.2858853455077625\n\n######################################## 폴드 3 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67679\tvalid-gini:0.15662\n[100]\tvalid-logloss:0.19334\tvalid-gini:0.24801\n[200]\tvalid-logloss:0.15931\tvalid-gini:0.27362\n[300]\tvalid-logloss:0.15589\tvalid-gini:0.28049\n[400]\tvalid-logloss:0.15540\tvalid-gini:0.28299\n[500]\tvalid-logloss:0.15531\tvalid-gini:0.28387\n[600]\tvalid-logloss:0.15529\tvalid-gini:0.28437\n[700]\tvalid-logloss:0.15528\tvalid-gini:0.28422\n[800]\tvalid-logloss:0.15526\tvalid-gini:0.28421\n[821]\tvalid-logloss:0.15527\tvalid-gini:0.28407\n폴드 3 지니계수 : 0.28443760405840407\n\n######################################## 폴드 4 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67679\tvalid-gini:0.18859\n[100]\tvalid-logloss:0.19326\tvalid-gini:0.24118\n[200]\tvalid-logloss:0.15944\tvalid-gini:0.26588\n[300]\tvalid-logloss:0.15609\tvalid-gini:0.27311\n[400]\tvalid-logloss:0.15560\tvalid-gini:0.27587\n[500]\tvalid-logloss:0.15550\tvalid-gini:0.27741\n[600]\tvalid-logloss:0.15547\tvalid-gini:0.27830\n[700]\tvalid-logloss:0.15544\tvalid-gini:0.27869\n[800]\tvalid-logloss:0.15543\tvalid-gini:0.27884\n[900]\tvalid-logloss:0.15542\tvalid-gini:0.27920\n[1000]\tvalid-logloss:0.15540\tvalid-gini:0.27930\n[1100]\tvalid-logloss:0.15540\tvalid-gini:0.27952\n[1200]\tvalid-logloss:0.15539\tvalid-gini:0.27978\n[1300]\tvalid-logloss:0.15539\tvalid-gini:0.27980\n[1400]\tvalid-logloss:0.15540\tvalid-gini:0.27958\n[1432]\tvalid-logloss:0.15540\tvalid-gini:0.27960\n폴드 4 지니계수 : 0.2799114042871249\n\n######################################## 폴드 5 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67680\tvalid-gini:0.17061\n[100]\tvalid-logloss:0.19339\tvalid-gini:0.24902\n[200]\tvalid-logloss:0.15953\tvalid-gini:0.27558\n[300]\tvalid-logloss:0.15610\tvalid-gini:0.28565\n[400]\tvalid-logloss:0.15556\tvalid-gini:0.29006\n[500]\tvalid-logloss:0.15540\tvalid-gini:0.29300\n[600]\tvalid-logloss:0.15536\tvalid-gini:0.29432\n[700]\tvalid-logloss:0.15530\tvalid-gini:0.29528\n[800]\tvalid-logloss:0.15529\tvalid-gini:0.29569\n[900]\tvalid-logloss:0.15526\tvalid-gini:0.29626\n[1000]\tvalid-logloss:0.15526\tvalid-gini:0.29655\n[1100]\tvalid-logloss:0.15525\tvalid-gini:0.29683\n[1200]\tvalid-logloss:0.15522\tvalid-gini:0.29681\n[1300]\tvalid-logloss:0.15523\tvalid-gini:0.29678\n[1320]\tvalid-logloss:0.15523\tvalid-gini:0.29689\n폴드 5 지니계수 : 0.2969046463729408\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds))","metadata":{"execution":{"iopub.status.busy":"2023-04-03T15:51:32.233837Z","iopub.execute_input":"2023-04-03T15:51:32.234208Z","iopub.status.idle":"2023-04-03T15:51:32.349166Z","shell.execute_reply.started":"2023-04-03T15:51:32.234173Z","shell.execute_reply":"2023-04-03T15:51:32.347815Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"OOF 검증 데이터 지니계수 : 0.28918135308145265\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5-4 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"submission['target'] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T15:53:53.566900Z","iopub.execute_input":"2023-04-03T15:53:53.567370Z","iopub.status.idle":"2023-04-03T15:53:55.810329Z","shell.execute_reply.started":"2023-04-03T15:53:53.567331Z","shell.execute_reply":"2023-04-03T15:53:55.808784Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}