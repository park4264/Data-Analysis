{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **3. 베이스라인 모델**\n\n- 이제부터 파이토치를 활용해 딥러닝 모델을 만들자\n\n- 파이토치를 활용한 딥러닝 모델링 절차는 다음과 같다:\n    1. **시드값 고정 및 GPU 장비 설정**\n    2. **데이터 준비**\n        1. 훈련/검증 데이터 분리\n        2. 데이터셋 클래스 정의\n        3. 데이터셋 생성\n        4. 데이터 로더 생성\n            - 데이터셋으로부터 데이터를 배치 단위로 불러와주는 객체\n    3. **모델 생성(CNN)**\n    4. **모델 훈련**\n        1. 손실 함수와 옵티마이저 설정\n        2. 모델 훈련\n    5. **성능 검증**\n    6. **예측 및 제출**","metadata":{}},{"cell_type":"markdown","source":"# 3-1. 시드값 고정 및 GPU 장비 설정\n\n## 3-1-1. 시드값 고정","metadata":{}},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)                # 파이썬 난수 생성기 시드 고정\nnp.random.seed(seed)             # 넘파이 난수 생성기 시드 고정\ntorch.manual_seed(seed)          # 파이토치 난수 생성기 시드 고정 (CPU 사용 시)\ntorch.cuda.manual_seed(seed)     # 파이토치 난수 생성기 시드 고정 (GPU 사용 시)\ntorch.cuda.manual_seed_all(seed) # 파이토치 난수 생성기 시드 고정 (멀티GPU 사용 시)\ntorch.backends.cudnn.deterministic = True # 확정적 연산 사용\ntorch.backends.cudnn.benchmark = False    # 벤치마크 기능 해제\ntorch.backends.cudnn.enabled = False      # cudnn 사용 해제","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-01T13:47:13.413834Z","iopub.execute_input":"2023-08-01T13:47:13.414266Z","iopub.status.idle":"2023-08-01T13:47:16.783359Z","shell.execute_reply.started":"2023-08-01T13:47:13.414202Z","shell.execute_reply":"2023-08-01T13:47:16.782322Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 3-1-2. GPU 장비 설정\n- 이어서 장비(device)를 설정해야 함\n- 비정형 데이터(이미지, 음성, 텍스트 등)를 모델링하려면 연산량이 많아진다.\n    - CPU로는 감당하기 벅찰 정도","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T13:47:16.868855Z","iopub.execute_input":"2023-08-01T13:47:16.871761Z","iopub.status.idle":"2023-08-01T13:47:16.904707Z","shell.execute_reply.started":"2023-08-01T13:47:16.871723Z","shell.execute_reply":"2023-08-01T13:47:16.903595Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2023-08-01T13:47:21.058097Z","iopub.execute_input":"2023-08-01T13:47:21.059542Z","iopub.status.idle":"2023-08-01T13:47:21.066371Z","shell.execute_reply.started":"2023-08-01T13:47:21.059497Z","shell.execute_reply":"2023-08-01T13:47:21.065171Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"- CUDA는 엔비디아에서 개발한 병렬 처리 플랫폼","metadata":{}},{"cell_type":"markdown","source":"# 3-2. 데이터 준비\n\n- 데이터 로더는 딥러닝 모델의 훈련에 필요한 데이터를 미니배치 단위로 공급하는 역할\n- 이때, 데이터셋 클래스에 정의된 변환기가 원본 데이터를 다양한 형태로 변환해준다.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T13:50:58.446700Z","iopub.execute_input":"2023-08-01T13:50:58.447058Z","iopub.status.idle":"2023-08-01T13:50:58.494733Z","shell.execute_reply.started":"2023-08-01T13:50:58.447028Z","shell.execute_reply":"2023-08-01T13:50:58.493843Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\n\n# 훈련 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \n# 테스트 이미지 데이터 압 풀기\nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T13:51:02.746579Z","iopub.execute_input":"2023-08-01T13:51:02.746933Z","iopub.status.idle":"2023-08-01T13:51:05.473263Z","shell.execute_reply.started":"2023-08-01T13:51:02.746905Z","shell.execute_reply":"2023-08-01T13:51:05.472293Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## 3-2-1. 훈련 데이터, 검증 데이터 분리","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(labels, \n                                test_size=0.1,\n                                stratify=labels['has_cactus'],\n                                random_state=50)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T13:52:24.542010Z","iopub.execute_input":"2023-08-01T13:52:24.542398Z","iopub.status.idle":"2023-08-01T13:52:25.335848Z","shell.execute_reply.started":"2023-08-01T13:52:24.542368Z","shell.execute_reply":"2023-08-01T13:52:25.334495Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"print('훈련 데이터 개수:', len(train))\nprint('검증 데이터 개수:', len(valid))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T13:52:29.188674Z","iopub.execute_input":"2023-08-01T13:52:29.189031Z","iopub.status.idle":"2023-08-01T13:52:29.197649Z","shell.execute_reply.started":"2023-08-01T13:52:29.189000Z","shell.execute_reply":"2023-08-01T13:52:29.196142Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"훈련 데이터 개수: 15750\n검증 데이터 개수: 1750\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3-2-2. 데이터셋 클래스 정의\n\n- 사용자 정의 데이터셋을 만들자\n- 파이토치로 신경망 모델을 구축하려면 데이터셋도 일정한 형식에 맞게 정의해야 함\n\n\n</br>\n\n- 파이토치에서 제공하는 `Dataset` 클래스를 활용해 데이터셋 객체를 만들 수 있다.\n- `Dataset`은 추상 클래스\n    - 추상 클래스는 곧바로 객체를 생성할 수 없고 상속만 할 수 있는 클래스를 일컫는다.\n    - 추상 클래스를 사용하는 이유는 상속받는 클래스들의 메서드를 규격화하기 위해서이다.\n    - 상속을 강제해 메서드 시그니처를 일치시킨다.\n    \n    \n</br>\n\n- 우리는 `Dataset`을 상속받은 다음, 특수 메서드인 `__len__()`과 `__getitem__()`을 재정의(오버라이딩)해야 함.\n    - `__len__()`: 데이터셋 크기를 반환\n    - `__getitem__()`: 인덱스를 전달받아 인덱스에 해당하는 데이터를 반환","metadata":{}},{"cell_type":"code","source":"import cv2 # OpenCV 라이브러리\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__() # 상속받은 Dataset의 생성자 호출\n        # 전달받은 인수들 저장\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드 \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]    # 이미지 ID\n        img_path = self.img_dir + img_id # 이미지 파일 경로 \n        image = cv2.imread(img_path)     # 이미지 파일 읽기 \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        label = self.df.iloc[idx, 1]     # 이미지 레이블(타깃값)\n\n        if self.transform is not None:\n            image = self.transform(image) # 변환기가 있다면 이미지 변환\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-08-01T13:56:44.843130Z","iopub.execute_input":"2023-08-01T13:56:44.843834Z","iopub.status.idle":"2023-08-01T13:56:45.020409Z","shell.execute_reply.started":"2023-08-01T13:56:44.843801Z","shell.execute_reply":"2023-08-01T13:56:45.019460Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 3-2-3. 데이터셋 생성\n- 앞서 정의한 `ImageDataset` 클래스를 이용하여 데이터셋을 만들어보자.\n- 파이토치 모델로 이미지를 다루려면 이미지 데이터를 **텐서(tensor)** 타입으로 바꿔야 한다.","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms # 이미지 변환을 위한 모듈\n\ntransform = transforms.ToTensor()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:06:09.297506Z","iopub.execute_input":"2023-08-01T14:06:09.297871Z","iopub.status.idle":"2023-08-01T14:06:09.495240Z","shell.execute_reply.started":"2023-08-01T14:06:09.297842Z","shell.execute_reply":"2023-08-01T14:06:09.494283Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"- `ToTensor()` 메서드로 이미지를 텐서로 바꿨다.\n    - (가로 픽셀 수, 세로 픽셀 수, 채널수) $\\Rightarrow$ (채널수, 가로 픽셀 수, 세로 픽셀 수)\n    - $32 \\times 32 \\times 3$ $\\Rightarrow$ $3 \\times 32 \\times 32$\n    \n    \n- 이제, 훈련 데이터셋과 검증 데이터셋을 만들자.\n    - 앞서 정의한 `ImageDataset()`클래스를 사용하면 된다.","metadata":{}},{"cell_type":"code","source":"dataset_train = ImageDataset(df=train, img_dir='train/', transform=transform)\ndataset_valid = ImageDataset(df=valid, img_dir='train/', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:09:39.429321Z","iopub.execute_input":"2023-08-01T14:09:39.430284Z","iopub.status.idle":"2023-08-01T14:09:39.435810Z","shell.execute_reply.started":"2023-08-01T14:09:39.430211Z","shell.execute_reply":"2023-08-01T14:09:39.434651Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## 3-2-4. 데이터 로더 생성\n\n- 데이터셋을 생성했다.\n- 그 다음으로는 지정한 배치 크기만큼씩 데이터를 불러오는 객체인 데이터 로더를 생성해야 함.\n    - 딥러닝 모델을 훈련할 때는 주로 배치 단위로 데이터를 가져와 훈련함.\n    - 배치의 크기는 2의 제곱수로 설정하는 것이 효율적","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:12:19.465061Z","iopub.execute_input":"2023-08-01T14:12:19.465430Z","iopub.status.idle":"2023-08-01T14:12:19.471471Z","shell.execute_reply.started":"2023-08-01T14:12:19.465400Z","shell.execute_reply":"2023-08-01T14:12:19.470347Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 3-3. 모델 생성","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nimport torch.nn.functional as F # 신경망 모듈에서 자주 사용되는 함수","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:13:58.690325Z","iopub.execute_input":"2023-08-01T14:13:58.690714Z","iopub.status.idle":"2023-08-01T14:13:58.696045Z","shell.execute_reply.started":"2023-08-01T14:13:58.690684Z","shell.execute_reply":"2023-08-01T14:13:58.694736Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"- CNN 모델은 `nn.Module`을 상속해 정의함\n- 그리고 순전파 후 결과를 반환하는 메서드인 `forward()`를 재정의\n- 참고로, 파이토치에서 `nn.Module`은 모든 신경망 모듈의 기반 클래스","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    # 신경망 계층 정의 \n    def __init__(self):\n        super().__init__() # 상속받은 nn.Module의 __init__() 메서드 호출\n        \n        # 첫 번째 합성곱 계층 \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, \n                               kernel_size=3, padding=2) \n        # 두 번째 합성곱 계층 \n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, \n                               kernel_size=3, padding=2) \n        # 최대 풀링 계층 \n        self.max_pool = nn.MaxPool2d(kernel_size=2) \n        # 평균 풀링 계층 \n        self.avg_pool = nn.AvgPool2d(kernel_size=2) \n        # 전결합 계층 \n        self.fc = nn.Linear(in_features=64 * 4 * 4, out_features=2)\n        \n    # 순전파 출력 정의 \n    def forward(self, x):\n        x = self.max_pool(F.relu(self.conv1(x)))\n        x = self.max_pool(F.relu(self.conv2(x)))\n        x = self.avg_pool(x)\n        x = x.view(-1, 64 * 4 * 4) # 평탄화\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:15:11.451865Z","iopub.execute_input":"2023-08-01T14:15:11.452251Z","iopub.status.idle":"2023-08-01T14:15:11.461467Z","shell.execute_reply.started":"2023-08-01T14:15:11.452205Z","shell.execute_reply":"2023-08-01T14:15:11.460281Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"- 마지막으로, 이렇게 정의한 `Model` 클래스로 CNN 모델을 생성하여 device 장비에 할당하자\n- 현재 device는 GPU를 사용하도록 설정되어있다.","metadata":{}},{"cell_type":"code","source":"model = Model().to(device)\n\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:24:59.476325Z","iopub.execute_input":"2023-08-01T14:24:59.476697Z","iopub.status.idle":"2023-08-01T14:25:02.645221Z","shell.execute_reply.started":"2023-08-01T14:24:59.476667Z","shell.execute_reply":"2023-08-01T14:25:02.644184Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Model(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (fc): Linear(in_features=1024, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3-4. 모델 훈련\n\n- 모델을 훈련하기 전, 손실 함수와 옵티마이저를 정의\n\n## 3-4-1. 손실 함수 설정\n\n- 가중치 갱신은 예측값과 실젯값의 손실이 작아지는 방향으로\n- 이때, 손실값을 구하는 함수가 손실 함수\n- 여기서는 손실 함수로 교차 엔트로피를 사용","metadata":{}},{"cell_type":"code","source":"# 손실함수\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:31:31.935776Z","iopub.execute_input":"2023-08-01T14:31:31.936136Z","iopub.status.idle":"2023-08-01T14:31:31.940768Z","shell.execute_reply.started":"2023-08-01T14:31:31.936105Z","shell.execute_reply":"2023-08-01T14:31:31.939765Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## 3-4-2. 옵티마이저 설정\n\n- 옵티마이저는 최적 가중치를 찾아주는 알고리즘\n- 기본 옵티마이저인 SGD로 설정","metadata":{}},{"cell_type":"code","source":"# 옵티마이저\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:32:09.291684Z","iopub.execute_input":"2023-08-01T14:32:09.292071Z","iopub.status.idle":"2023-08-01T14:32:09.297589Z","shell.execute_reply.started":"2023-08-01T14:32:09.292031Z","shell.execute_reply":"2023-08-01T14:32:09.296496Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 3-4-3. 모델 훈련\n\n- 이미지용 딥러닝 모델 훈련 절차는 다음과 같다.\n\n1. 데이터 로더에서 배치 크기만큼 데이터를 불러온다.\n2. 불러온 이미지 데이터와 레이블(타깃값) 데이터를 장비(GPU 혹은 CPU)에 할당한다.\n3. 옵티마이저 내 기울기를 초기화한다.\n4. 신경망 모델에 입력 데이터(이미지)를 전달해 순전파하여 출력값(예측값)을 구한다.\n5. 예측값과 실제 레이블(타깃값)을 비교해 손실을 계산한다.\n6. 손실을 기반으로 역전파를 수행한다.\n7. 역전파로 구한 기울기를 활용해 가중치를 갱신한다.\n8. 1~7 절차를 반복 횟수만큼 되풀이한다.\n9. 1~8 절차를 에폭만큼 반복한다.","metadata":{}},{"cell_type":"code","source":"epochs = 10 # 총 에폭\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    epoch_loss = 0 # 에폭별 손실값 초기화\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in loader_train:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가\n        epoch_loss += loss.item() \n        # 역전파 수행\n        loss.backward()\n        # 가중치 갱신\n        optimizer.step()\n        \n    # 훈련 데이터 손실값 출력\n    print(f'에폭 [{epoch+1}/{epochs}] - 손실값: {epoch_loss/len(loader_train):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:36:07.610384Z","iopub.execute_input":"2023-08-01T14:36:07.611291Z","iopub.status.idle":"2023-08-01T14:36:59.910276Z","shell.execute_reply.started":"2023-08-01T14:36:07.611224Z","shell.execute_reply":"2023-08-01T14:36:59.909283Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"에폭 [1/10] - 손실값: 0.5233\n에폭 [2/10] - 손실값: 0.3453\n에폭 [3/10] - 손실값: 0.2370\n에폭 [4/10] - 손실값: 0.1984\n에폭 [5/10] - 손실값: 0.1754\n에폭 [6/10] - 손실값: 0.1666\n에폭 [7/10] - 손실값: 0.1545\n에폭 [8/10] - 손실값: 0.1439\n에폭 [9/10] - 손실값: 0.1333\n에폭 [10/10] - 손실값: 0.1299\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3-5. 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수 임포트\n\n# 실제값과 예측 확률값을 담을 리스트 초기화\ntrue_list = []\npreds_list = []","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:39:13.208728Z","iopub.execute_input":"2023-08-01T14:39:13.209099Z","iopub.status.idle":"2023-08-01T14:39:13.214338Z","shell.execute_reply.started":"2023-08-01T14:39:13.209061Z","shell.execute_reply":"2023-08-01T14:39:13.213293Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.eval() # 모델을 평가 상태로 설정 \n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, labels in loader_valid:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device) \n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        preds = torch.softmax(outputs.cpu(), dim=1)[:, 1] # 예측 확률  \n        true = labels.cpu() # 실제값 \n        # 예측 확률과 실제값을 리스트에 추가\n        preds_list.extend(preds)\n        true_list.extend(true)\n        \n# 검증 데이터 ROC AUC 점수 계산\nprint(f'검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:39:56.676856Z","iopub.execute_input":"2023-08-01T14:39:56.677217Z","iopub.status.idle":"2023-08-01T14:39:57.253967Z","shell.execute_reply.started":"2023-08-01T14:39:56.677187Z","shell.execute_reply":"2023-08-01T14:39:57.253030Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"검증 데이터 ROC AUC : 0.990\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3-6. 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(df=submission, img_dir='test/', transform=transform)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:42:29.775322Z","iopub.execute_input":"2023-08-01T14:42:29.775703Z","iopub.status.idle":"2023-08-01T14:42:29.782313Z","shell.execute_reply.started":"2023-08-01T14:42:29.775672Z","shell.execute_reply":"2023-08-01T14:42:29.780243Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## 3-6-1. 예측","metadata":{}},{"cell_type":"code","source":"model.eval() # 모델을 평가 상태로 설정\n\npreds = [] # 타깃 예측값 저장용 리스트 초기화\n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, _ in loader_test:\n        # 이미지 데이터 미니배치를 장비에 할당\n        images = images.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 타깃값이 1일 확률(예측값)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        # preds에 preds_part 이어붙이기\n        preds.extend(preds_part)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:42:38.823125Z","iopub.execute_input":"2023-08-01T14:42:38.823841Z","iopub.status.idle":"2023-08-01T14:42:39.970794Z","shell.execute_reply.started":"2023-08-01T14:42:38.823806Z","shell.execute_reply":"2023-08-01T14:42:39.969744Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## 3-6-2. 결과 제출","metadata":{}},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:44:18.794997Z","iopub.execute_input":"2023-08-01T14:44:18.795400Z","iopub.status.idle":"2023-08-01T14:44:18.827055Z","shell.execute_reply.started":"2023-08-01T14:44:18.795368Z","shell.execute_reply":"2023-08-01T14:44:18.826039Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"- 이제 제출 전에 훈련 이미지 데이터와 테스트 이미지 데이터를 모두 삭제","metadata":{}},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T14:46:35.373218Z","iopub.execute_input":"2023-08-01T14:46:35.373604Z","iopub.status.idle":"2023-08-01T14:46:36.020521Z","shell.execute_reply.started":"2023-08-01T14:46:35.373572Z","shell.execute_reply":"2023-08-01T14:46:36.019519Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}