{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **4. 성능 개선**\n\n이번 절에서는 다음 네 가지를 개선해 성능을 높이자\n\n1. 다양한 이미지 변환을 수행\n2. 더 깊은 CNN 모델을 만들자\n3. 더 뛰어난 옵티마이저를 사용하자\n4. 훈련 시 에폭 수를 늘리자\n\n절차는 다음과 같다\n1. **시드값 고정 및 GPU 장비 설정**\n2. **데이터 준비**\n    1. 훈련/검증 데이터 분리\n    2. 데이터셋 클래스 정의\n    3. <u> 이미지 변환기 정의 </u>\n    4. 데이터셋 생성\n    5. 데이터 로더 생성\n    \n3. **모델 생성(<u> 깊은 CNN </u>)**\n    - <u> 배치 정규화, Leaky ReLU </u>\n    \n4. **모델 훈련**\n    1. 손실 함수와 <u> 더 좋은 </u>옵티마이저 설정\n    2. 모델 훈련 <u> (에폭 수 증가) </u>\n5. **성능 검증**\n6. **예측 및 제출**","metadata":{}},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-01T15:39:08.831024Z","iopub.execute_input":"2023-08-01T15:39:08.831473Z","iopub.status.idle":"2023-08-01T15:39:08.839313Z","shell.execute_reply.started":"2023-08-01T15:39:08.831437Z","shell.execute_reply":"2023-08-01T15:39:08.838244Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:08.844609Z","iopub.execute_input":"2023-08-01T15:39:08.845715Z","iopub.status.idle":"2023-08-01T15:39:08.854186Z","shell.execute_reply.started":"2023-08-01T15:39:08.845675Z","shell.execute_reply":"2023-08-01T15:39:08.853117Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# 4-1. 데이터 준비","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:08.857636Z","iopub.execute_input":"2023-08-01T15:39:08.857940Z","iopub.status.idle":"2023-08-01T15:39:08.889636Z","shell.execute_reply.started":"2023-08-01T15:39:08.857915Z","shell.execute_reply":"2023-08-01T15:39:08.888755Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\n\n# 훈련 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \n# 테스트 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:08.891092Z","iopub.execute_input":"2023-08-01T15:39:08.891670Z","iopub.status.idle":"2023-08-01T15:39:13.679175Z","shell.execute_reply.started":"2023-08-01T15:39:08.891637Z","shell.execute_reply":"2023-08-01T15:39:13.678141Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(labels, \n                                test_size=0.1,\n                                stratify=labels['has_cactus'],\n                                random_state=50)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.680547Z","iopub.execute_input":"2023-08-01T15:39:13.681228Z","iopub.status.idle":"2023-08-01T15:39:13.701477Z","shell.execute_reply.started":"2023-08-01T15:39:13.681189Z","shell.execute_reply":"2023-08-01T15:39:13.700509Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import cv2 # OpenCV 라이브러리\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__() # 상속받은 Dataset의 생성자 호출\n        # 전달받은 인수들 저장\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드 \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]    # 이미지 ID\n        img_path = self.img_dir + img_id # 이미지 파일 경로 \n        image = cv2.imread(img_path)     # 이미지 파일 읽기 \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        label = self.df.iloc[idx, 1]     # 이미지 레이블(타깃값)\n\n        if self.transform is not None:\n            image = self.transform(image) # 변환기가 있다면 이미지 변환\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.704675Z","iopub.execute_input":"2023-08-01T15:39:13.705285Z","iopub.status.idle":"2023-08-01T15:39:13.715984Z","shell.execute_reply.started":"2023-08-01T15:39:13.705253Z","shell.execute_reply":"2023-08-01T15:39:13.715063Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 4-1-1. 이미지 변환과 데이터 증강\n\n## 4-1-2. 이미지 변환기 정의","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms # 이미지 변환을 위한 모듈\n\n# 훈련 데이터용 변환기\ntransform_train = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Pad(32, padding_mode='symmetric'),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),\n                                      transforms.RandomRotation(10),\n                                      transforms.Normalize((0.485, 0.456, 0.406),\n                                                           (0.229, 0.224, 0.225))])\n\n# 검증 및 테스트 데이터용 변환기\ntransform_test= transforms.Compose([transforms.ToTensor(),\n                                    transforms.Pad(32, padding_mode='symmetric'),\n                                    transforms.Normalize((0.485, 0.456, 0.406),\n                                                         (0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.717657Z","iopub.execute_input":"2023-08-01T15:39:13.718260Z","iopub.status.idle":"2023-08-01T15:39:13.731294Z","shell.execute_reply.started":"2023-08-01T15:39:13.718228Z","shell.execute_reply":"2023-08-01T15:39:13.730160Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## 4-1-3. 데이터셋 및 데이터 로더 생성","metadata":{}},{"cell_type":"code","source":"dataset_train = ImageDataset(df=train, img_dir='train/', transform=transform_train)\ndataset_valid = ImageDataset(df=valid, img_dir='train/', transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.735569Z","iopub.execute_input":"2023-08-01T15:39:13.736316Z","iopub.status.idle":"2023-08-01T15:39:13.748087Z","shell.execute_reply.started":"2023-08-01T15:39:13.736275Z","shell.execute_reply":"2023-08-01T15:39:13.747265Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.751340Z","iopub.execute_input":"2023-08-01T15:39:13.752066Z","iopub.status.idle":"2023-08-01T15:39:13.766356Z","shell.execute_reply.started":"2023-08-01T15:39:13.752026Z","shell.execute_reply":"2023-08-01T15:39:13.765226Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# 4-2. 모델 생성","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nimport torch.nn.functional as F # 신경망 모듈에서 자주 사용되는 함수\n\nclass Model(nn.Module):\n    # 신경망 계층 정의\n    def __init__(self):\n        super().__init__() # 상속받은 nn.Module의 __init__() 메서드 호출\n        # 1 ~ 5번째 {합성곱, 배치 정규화, 최대 풀링} 계층 \n        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(32), # 배치 정규화\n                                    nn.LeakyReLU(), # LeakyReLU 활성화 함수\n                                    nn.MaxPool2d(kernel_size=2))\n\n        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(64),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer3 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(128),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer4 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(256),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer5 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(512),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        # 평균 풀링 계층 \n        self.avg_pool = nn.AvgPool2d(kernel_size=4) \n        # 전결합 계층\n        self.fc1 = nn.Linear(in_features=512 * 1 * 1, out_features=64)\n        self.fc2 = nn.Linear(in_features=64, out_features=2)\n\n    # 순전파 출력 정의 \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.avg_pool(x)\n        x = x.view(-1, 512 * 1 * 1) # 평탄화\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.769774Z","iopub.execute_input":"2023-08-01T15:39:13.770515Z","iopub.status.idle":"2023-08-01T15:39:13.794352Z","shell.execute_reply.started":"2023-08-01T15:39:13.770465Z","shell.execute_reply":"2023-08-01T15:39:13.793207Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.799255Z","iopub.execute_input":"2023-08-01T15:39:13.802003Z","iopub.status.idle":"2023-08-01T15:39:13.840991Z","shell.execute_reply.started":"2023-08-01T15:39:13.801967Z","shell.execute_reply":"2023-08-01T15:39:13.840043Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# 4-3. 모델 훈련","metadata":{}},{"cell_type":"code","source":"# 손실 함수\ncriterion = nn.CrossEntropyLoss()\n# 옵티마이저\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.00006)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.845458Z","iopub.execute_input":"2023-08-01T15:39:13.847998Z","iopub.status.idle":"2023-08-01T15:39:13.855377Z","shell.execute_reply.started":"2023-08-01T15:39:13.847962Z","shell.execute_reply":"2023-08-01T15:39:13.854407Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"epochs = 70 # 총 에폭\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    epoch_loss = 0 # 에폭별 손실값 초기화\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in loader_train:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가\n        epoch_loss += loss.item() \n        # 역전파 수행\n        loss.backward()\n        # 가중치 갱신\n        optimizer.step()\n        \n    print(f'에폭 [{epoch+1}/{epochs}] - 손실값: {epoch_loss/len(loader_train):.3f}')   ","metadata":{"execution":{"iopub.status.busy":"2023-08-01T15:39:13.859739Z","iopub.execute_input":"2023-08-01T15:39:13.862411Z","iopub.status.idle":"2023-08-01T16:22:53.015780Z","shell.execute_reply.started":"2023-08-01T15:39:13.862375Z","shell.execute_reply":"2023-08-01T16:22:53.014510Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"에폭 [1/70] - 손실값: 0.129\n에폭 [2/70] - 손실값: 0.066\n에폭 [3/70] - 손실값: 0.048\n에폭 [4/70] - 손실값: 0.042\n에폭 [5/70] - 손실값: 0.034\n에폭 [6/70] - 손실값: 0.035\n에폭 [7/70] - 손실값: 0.031\n에폭 [8/70] - 손실값: 0.027\n에폭 [9/70] - 손실값: 0.025\n에폭 [10/70] - 손실값: 0.026\n에폭 [11/70] - 손실값: 0.023\n에폭 [12/70] - 손실값: 0.023\n에폭 [13/70] - 손실값: 0.020\n에폭 [14/70] - 손실값: 0.021\n에폭 [15/70] - 손실값: 0.020\n에폭 [16/70] - 손실값: 0.017\n에폭 [17/70] - 손실값: 0.016\n에폭 [18/70] - 손실값: 0.017\n에폭 [19/70] - 손실값: 0.016\n에폭 [20/70] - 손실값: 0.016\n에폭 [21/70] - 손실값: 0.014\n에폭 [22/70] - 손실값: 0.015\n에폭 [23/70] - 손실값: 0.012\n에폭 [24/70] - 손실값: 0.012\n에폭 [25/70] - 손실값: 0.014\n에폭 [26/70] - 손실값: 0.011\n에폭 [27/70] - 손실값: 0.012\n에폭 [28/70] - 손실값: 0.013\n에폭 [29/70] - 손실값: 0.011\n에폭 [30/70] - 손실값: 0.011\n에폭 [31/70] - 손실값: 0.010\n에폭 [32/70] - 손실값: 0.010\n에폭 [33/70] - 손실값: 0.010\n에폭 [34/70] - 손실값: 0.010\n에폭 [35/70] - 손실값: 0.009\n에폭 [36/70] - 손실값: 0.010\n에폭 [37/70] - 손실값: 0.007\n에폭 [38/70] - 손실값: 0.007\n에폭 [39/70] - 손실값: 0.007\n에폭 [40/70] - 손실값: 0.010\n에폭 [41/70] - 손실값: 0.007\n에폭 [42/70] - 손실값: 0.010\n에폭 [43/70] - 손실값: 0.008\n에폭 [44/70] - 손실값: 0.008\n에폭 [45/70] - 손실값: 0.007\n에폭 [46/70] - 손실값: 0.006\n에폭 [47/70] - 손실값: 0.005\n에폭 [48/70] - 손실값: 0.007\n에폭 [49/70] - 손실값: 0.005\n에폭 [50/70] - 손실값: 0.006\n에폭 [51/70] - 손실값: 0.004\n에폭 [52/70] - 손실값: 0.008\n에폭 [53/70] - 손실값: 0.006\n에폭 [54/70] - 손실값: 0.006\n에폭 [55/70] - 손실값: 0.005\n에폭 [56/70] - 손실값: 0.006\n에폭 [57/70] - 손실값: 0.005\n에폭 [58/70] - 손실값: 0.006\n에폭 [59/70] - 손실값: 0.007\n에폭 [60/70] - 손실값: 0.005\n에폭 [61/70] - 손실값: 0.004\n에폭 [62/70] - 손실값: 0.004\n에폭 [63/70] - 손실값: 0.004\n에폭 [64/70] - 손실값: 0.004\n에폭 [65/70] - 손실값: 0.005\n에폭 [66/70] - 손실값: 0.006\n에폭 [67/70] - 손실값: 0.004\n에폭 [68/70] - 손실값: 0.005\n에폭 [69/70] - 손실값: 0.004\n에폭 [70/70] - 손실값: 0.003\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4-4. 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수 임포트\n\n# 실제값과 예측 확률값을 담을 리스트 초기화\ntrue_list = []\npreds_list = []\n\nmodel.eval() # 모델을 평가 상태로 설정 \n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, labels in loader_valid:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        preds = torch.softmax(outputs.cpu(), dim=1)[:, 1] # 예측 확률값\n        true = labels.cpu() # 실제값 \n        # 예측 확률값과 실제값을 리스트에 추가\n        preds_list.extend(preds)\n        true_list.extend(true)\n        \n# 검증 데이터 ROC AUC 점수 계산 \nprint(f'검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}')    ","metadata":{"execution":{"iopub.status.busy":"2023-08-01T16:22:53.019674Z","iopub.execute_input":"2023-08-01T16:22:53.020021Z","iopub.status.idle":"2023-08-01T16:22:55.265541Z","shell.execute_reply.started":"2023-08-01T16:22:53.019994Z","shell.execute_reply":"2023-08-01T16:22:55.264592Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"검증 데이터 ROC AUC : 0.9998\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4-5. 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(df=submission, img_dir='test/', \n                            transform=transform_test)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)\n\n# 예측 수행\nmodel.eval() # 모델을 평가 상태로 설정\n\npreds = [] # 타깃 예측값 저장용 리스트 초기화\n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, _ in loader_test:\n        # 이미지 데이터 미니배치를 장비에 할당\n        images = images.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 타깃값이 1일 확률(예측값)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        # preds에 preds_part 이어붙이기\n        preds.extend(preds_part)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T16:22:55.266948Z","iopub.execute_input":"2023-08-01T16:22:55.267753Z","iopub.status.idle":"2023-08-01T16:23:00.330930Z","shell.execute_reply.started":"2023-08-01T16:22:55.267725Z","shell.execute_reply":"2023-08-01T16:23:00.329877Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T16:23:00.332541Z","iopub.execute_input":"2023-08-01T16:23:00.332924Z","iopub.status.idle":"2023-08-01T16:23:00.360568Z","shell.execute_reply.started":"2023-08-01T16:23:00.332889Z","shell.execute_reply":"2023-08-01T16:23:00.359345Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T16:23:00.362114Z","iopub.execute_input":"2023-08-01T16:23:00.362592Z","iopub.status.idle":"2023-08-01T16:23:01.016338Z","shell.execute_reply.started":"2023-08-01T16:23:00.362555Z","shell.execute_reply":"2023-08-01T16:23:01.014938Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}