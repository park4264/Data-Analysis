# **Part II. 머신러닝 문제해결**








# **Chapter 8. [경진대회] 안전 운전자 예측 경진대회**
### **Predict Future Sales**
### Final project for "How to win a data science competition" Coursera course

![img](./img/2-6-1.png)

- [Kaggle Link](https://www.kaggle.com/competitions/competitive-data-science-predict-future-sales)


</br>
</br>


# 0. 경진대회 이해 💁🏻‍♂️

- **Goal**: 과거 판매 데이터를 보고 향후 판매량을 예측

- **회귀 문제**


</br>

## 0-1. 데이터 특징 📚


- 주어진 훈련 데이터는 2013년 1월부터 2015년 10월까지의 일별 판매 내역
- ➕ 더불어 상점, 상품, 상품분류에 관한 추가 데이터도 있다.
- <u>이 데이터들을 토대로 2015년 11월 각 상점의 상품별 월간 판매량을 예측해야 함</u>

</br>

- **피처**: 상점 및 상품에 관한 정보
- **타깃값**: 월간 판매량



</br>



- 제공 데이터파일 6개: 훈련 데이터 + 관련된 추가 데이터
    - `sales_train`: 2013년 1월부터 2015년 10월까지 일별 판매 내역
    - **`shops`**: 상점에 관한 추가 정보 🫧
    - **`items`**: 상품에 관한 추가 정보 🫧
    - **`itme_categories`**: 상품분류에 관한 추가 정보 🫧
    - `test`: 테스트 데이터 (2015년 11월 각 상점의 상품별 월간 판매량을 예측해야 함)
    - `sample_submission`: 샘플 제출 파일

- 주의점: 각 상점의 상품별 월간 판매량(타깃값)은 0개에서 20개 사이여야 한다.













</br>
</br>













# 1. 분석 정리 및 모델링 전략

## 1-1. 분석 정리

1. 대회의 타깃값 규정 상, 판매량 관련 피처의 값은 모두 0~20 사이로 제한해야 함


2. 시계열 데이터이므로 데이터 순서를 꼭 지켜야 함
    - OOF 예측 등 데이터 순서가 무시되는 기법은 사용할 수 없음
    - 검증 데이터는 훈련 데이터 중 최근 1개월치를 이용


3. **타깃값**
    - 월별 판매량을 예측해야 하나, 주어진 데이터에는 일별 판매량만 있음
    - 같은 달의 일별 판매량을 합쳐 타깃값을 구해야 함




4. **데이터 병합**
    - 추가 정포 파일(상점, 상품, 상품분류)은 각각의 ID (상점 ID, 상품 ID, 상품분류 ID)를 기준으로 훈련 데이터에 병합할 수 있다.




5. 다양한 피처 엔지니어링 후에 데이터 크기가 커져서 메모리 관리가 필요




6. **파생 피처 추가**: 상점명과 상품분류명의 첫 단어는 각각 도시와 대분류를 뜻한다.
    

7. **피처 제거**: 월별 판매량만 구하면 되니 `date` 피처는 필요 없음


8. **피처 제거**: 상점ID, 상품ID, 상품분류ID는 각각 상점명, 상품명, 상품분류명과 1:1로 매칭되므로 둘 중 하나만 있으면 된다.


</br>



## 1-2. 모델링 전략


- 이번 대회는 피처 엔지니어링에 집중
- 다른 모델링 요소는 최소한만 수행
- 특히 성능 개선 단계에서는 위 분석 정리에서 미처 발견하지 못한 피처 엔지니어링도 수행


- **베이스라인 모델**: LightBGM
    - **피처 엔지니어링**: 피처명 한글화, 데이터 다운캐스팅, 데이터 조합 생성, 타깃값 추가
    
- **성능 개선 1**: LightBGM 유지
    - **피처 엔지니어링**: 이상치 제거, 전처리 등 다양한 파생 피처 추가, 인코딩, 결측값 처리
    

</br>
</br>

# 2. 요약

- 피처별 타깃값 예측력을 기반으로 모델링에 필요 없는 데이터를 선별하는 방법을 익혔다.
- 캐글에서 자주 사용하는 LightGBM과 XGBoost 모델 사용법도 익혔다.
- OOF 예측, 베이지안 최적화, 앙상블 기법을 활용해 예측 성능을 높였다.

## 2-1. 핵심

1. **정규화 지니계수**
    - 예측값에 대한 지니계수 / 예측이 완벽할 때의 지니계수
    - 직접 정의해서 써야 함

2. **피처 요약표**
    - 데이터의 성격에 맞게 조금씩 변형해 사용

3. **결측값 시각화**: `missingno` 패키지가 유용

4. **결측값 처리**: 방법 보통 세 가지
    - 결측값이 많으면 해당 피처 자체를 제거 / 많이 않다면 다른 값으로 대체
    - 때로는 결측값이 도움 - 이럴 때는 결측값을 하나의 고윳값으로 간주

5. **피처 엔지니어링**: 상당한 창의력 요구
    - 사칙연산, 통계치, 문자열 연결 같은 방법을 시도
    - 다른 캐글러들의 방법도 참고하며 경험과 응용력을 쌓자

6. **베이지안 최적화**
    - 그리드서치보다 하이퍼파라미터를 더 빠르고 효율적으로 찾아줌

7. **OOF 예측**
    - K 폴드 교차 검증을 수행하면서 각 폴드마다 테스트 데이터로 예측하는 방식
    - 과대적합 방지 및 앙상블 효과

8. **LightGBM**
    - 마이크로소프트가 개발한 모델
    - 빠르면서 성능이 좋아 캐글에서 많이 사용함

9. **XGBoost**
    - 성능이 우수한 트리 기반 부스팅 알고리즘
    - 결정 트리를 병렬로 배치하는 랜덤 포레스트와 달리 직렬로 배치해 사용

10. **앙상블**
    - 여러 모델에서 얻은 예측 결과를 결합해 더 좋은 예측값을 도출하는 방식
    - 단순하면서 효과가 좋음

    