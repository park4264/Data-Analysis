# **Part II. 머신러닝 문제해결**








# **Chapter 8. [경진대회] 안전 운전자 예측 경진대회**
### **Porto Seguro’s Safe Driver Prediction**
### Predict if a driver will file an insurance claim next year.

![img](./img/2-6-1.png)

- [Kaggle Link](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction)


</br>
</br>


# 0. 경진대회 이해 💁🏻‍♂️

- **Goal**: 운전자가 보험금을 청구할 확률을 정확히 예측하는 모델 제작

## 0-1. 주어진 데이터 특정

- 주어진 데이터는 포르투 세구로가 보유한 고객 데이터
- 결측값이 많음
    - 결측값은 `-1`로 기록

- 타깃값은 `0` 또는 `1`
    - `0`: 운전자가 보험금을 청구하지 않음
    - `1`: 청구
    - 타깃값이 두 개이므로 본 대회는 **이진분류 문제**

</br>
</br>













# 1. 분석 정리 및 모델링 전략

## 1-1. 분석 정리

1. 데이터가 크고 피처도 많다.
2. 피처명만으로 분류별 혹은 데이터 종류별 피처들을 구분해 추출할 수 있다.
3. **결측값 처리**: 결측값 자체에 타깃값 예측력이 있다면 고윳값으로 간주
4. **결측값 처리**: 피처 간 상관관계 분석은 결측값 제거 후 수행
5. **피처 제거**: 신뢰구간이 넓으면 믿을 수 없음
    - `ps_ind_14`, `ps_calc_04` ~ `ps_calc_14`
6. **피처 제거**: 고윳값별 타깃값 비율에 차이가 없다면 타깃값 예측력이 없음
    - `ps_calc_04` ~ `ps_calc_14`

7. **피처 제거**: (연속형 데이터의 경우) 구간별 타깃값 차이가 거의 없다면 타깃값 예측력이 없음
    - `ps_calc_01` ~ `ps_calc_03`

8. **피처 제거**: 일반적으로 강한 상관관계를 보이는 두 피처가 있으면 둘 중 하나를 제거하는게 좋음
    - `ps_car_14`




## 1-2. 모델링 전략


- 캐글에서 실제로 많이 활용되는 여러 가지 고급 모델링 기법을 적용할 것
- 주요 키워드: 
    - `OOF 예측`, `베이지안 최적화`, `LightGBM`, `XGBoost`, `앙상블`

- **베이스라인 모델**: LightBGM
    - **훈련 및 예측**: OOF 예측 (과대적합 방지 + 앙상블 효과)
- **성능 개선 1**: LightBGM 유지
    - **피처 엔지니어링**: 파생 피처 추가
    - **하이퍼파라미터 최적화**: 베이지안 최적화

- **성능 개선 2**: XGBoost (모델만 변경)

- **성능 개선 3**: LightBGM + XGBoost 앙상블








</br>
</br>

# 2. 요약

- 피처별 타깃값 예측력을 기반으로 모델링에 필요 없는 데이터를 선별하는 방법을 익혔다.
- 캐글에서 자주 사용하는 LightGBM과 XGBoost 모델 사용법도 익혔다.
- OOF 예측, 베이지안 최적화, 앙상블 기법을 활용해 예측 성능을 높였다.

## 2-1. 핵심

1. **정규화 지니계수**
    - 예측값에 대한 지니계수 / 예측이 완벽할 때의 지니계수
    - 직접 정의해서 써야 함

2. **피처 요약표**
    - 데이터의 성격에 맞게 조금씩 변형해 사용

3. **결측값 시각화**: `missingno` 패키지가 유용

4. **결측값 처리**: 방법 보통 세 가지
    - 결측값이 많으면 해당 피처 자체를 제거 / 많이 않다면 다른 값으로 대체
    - 때로는 결측값이 도움 - 이럴 때는 결측값을 하나의 고윳값으로 간주

5. **피처 엔지니어링**: 상당한 창의력 요구
    - 사칙연산, 통계치, 문자열 연결 같은 방법을 시도
    - 다른 캐글러들의 방법도 참고하며 경험과 응용력을 쌓자

6. **베이지안 최적화**
    - 그리드서치보다 하이퍼파라미터를 더 빠르고 효율적으로 찾아줌

7. **OOF 예측**
    - K 폴드 교차 검증을 수행하면서 각 폴드마다 테스트 데이터로 예측하는 방식
    - 과대적합 방지 및 앙상블 효과

8. **LightGBM**
    - 마이크로소프트가 개발한 모델
    - 빠르면서 성능이 좋아 캐글에서 많이 사용함

9. **XGBoost**
    - 성능이 우수한 트리 기반 부스팅 알고리즘
    - 결정 트리를 병렬로 배치하는 랜덤 포레스트와 달리 직렬로 배치해 사용

10. **앙상블**
    - 여러 모델에서 얻은 예측 결과를 결합해 더 좋은 예측값을 도출하는 방식
    - 단순하면서 효과가 좋음

    