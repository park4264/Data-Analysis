{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 3. 베이스라인 모델\n\n- 앞에서 선별한 피처들을 제거해 베이스라인 모델을 만들자\n- **LightBGM**: 마이스로소프트가 개발한 모델, 빠르면서 성능이 좋음","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\n\ntrain = pd.read_csv(data_path + 'train.csv', index_col='id')\ntest = pd.read_csv(data_path + 'test.csv', index_col='id')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-03T07:41:24.775155Z","iopub.execute_input":"2023-04-03T07:41:24.775747Z","iopub.status.idle":"2023-04-03T07:41:38.465126Z","shell.execute_reply.started":"2023-04-03T07:41:24.775666Z","shell.execute_reply":"2023-04-03T07:41:38.463630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-1. 피처 엔지니어링\n\n### 3-1-1. 데이터 합치기","metadata":{}},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop('target', axis=1) # 타깃값 제거","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:47:16.023770Z","iopub.execute_input":"2023-04-03T07:47:16.024253Z","iopub.status.idle":"2023-04-03T07:47:17.455132Z","shell.execute_reply.started":"2023-04-03T07:47:16.024211Z","shell.execute_reply":"2023-04-03T07:47:17.453683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_features = all_data.columns # 전체 피처\nall_features","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:47:35.321584Z","iopub.execute_input":"2023-04-03T07:47:35.322046Z","iopub.status.idle":"2023-04-03T07:47:35.331832Z","shell.execute_reply.started":"2023-04-03T07:47:35.322002Z","shell.execute_reply":"2023-04-03T07:47:35.330425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3-1-2. 명목형 피처 원-핫 인코딩\n\n- 모든 명목형 피처에 원-핫 인코딩을 적용","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# 명목형 피처 추출\ncat_features = [feature for feature in all_features if 'cat' in feature] \n\nonehot_encoder = OneHotEncoder() # 원-핫 인코더 객체 생성\n# 인코딩\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features]) \n\nencoded_cat_matrix","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:50:06.872663Z","iopub.execute_input":"2023-04-03T07:50:06.873227Z","iopub.status.idle":"2023-04-03T07:50:08.903739Z","shell.execute_reply.started":"2023-04-03T07:50:06.873171Z","shell.execute_reply":"2023-04-03T07:50:08.902413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 원-핫 인코딩을 하니 열이 184개나 생김!\n\n### 3-1-3. 필요 없는 피처 제거","metadata":{}},{"cell_type":"code","source":"# 추가로 제거할 피처\ndrop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', \n                 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n\n# '1) 명목형 피처, 2) calc 분류의 피처, 3) 추가 제거할 피처'를 제외한 피처\nremaining_features = [feature for feature in all_features \n                      if ('cat' not in feature and \n                          'calc' not in feature and \n                          feature not in drop_features)]","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:50:09.973620Z","iopub.execute_input":"2023-04-03T07:50:09.974560Z","iopub.status.idle":"2023-04-03T07:50:09.982274Z","shell.execute_reply.started":"2023-04-03T07:50:09.974507Z","shell.execute_reply":"2023-04-03T07:50:09.980381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import sparse\n\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data[remaining_features]),\n                               encoded_cat_matrix],\n                              format='csr')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:50:26.056871Z","iopub.execute_input":"2023-04-03T07:50:26.058168Z","iopub.status.idle":"2023-04-03T07:50:28.766105Z","shell.execute_reply.started":"2023-04-03T07:50:26.058112Z","shell.execute_reply":"2023-04-03T07:50:28.764998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3-1-4. 데이터 나누기","metadata":{}},{"cell_type":"code","source":"num_train = len(train) # 훈련 데이터 개수\n\n# 훈련 데이터와 테스트 데이터 나누기\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\n\ny = train['target'].values","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:50:39.790092Z","iopub.execute_input":"2023-04-03T07:50:39.790487Z","iopub.status.idle":"2023-04-03T07:50:40.556127Z","shell.execute_reply.started":"2023-04-03T07:50:39.790453Z","shell.execute_reply":"2023-04-03T07:50:40.554745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-2. 평가지표 계산 함수 작성\n\n- 본 경진대회의 평가지표는 정규화된 지니계수\n    - 파이썬이나 사이킷런에서 기본으로 제공하지 않으므로 직접 만들어야 함\n    \n### 3-2-1. 지니계수란?\n\n- 경제학에서 지니계수는 소득 불평등 정도를 나타내는 지표\n- 지니계수가 작을수록 소득 수준이 평등 / 클수록 불평등\n- 로렌츠 곡선을 이용해 계산\n\n### 3-2-2. 정규화 지니계수 계산 함수\n\n- 정규화 지니계수 = 예측 값에 대한 지니 계수 / 예측이 완벽할 때의 지니 계수","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n    assert y_true.shape == y_pred.shape\n\n    n_samples = y_true.shape[0]                      # 데이터 개수\n    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n\n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n\n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n    G_true = np.sum(L_mid - L_true)       # 예측이 완벽할 때 지니계수\n\n    # 정규화된 지니계수\n    return G_pred / G_true","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:55:43.520583Z","iopub.execute_input":"2023-04-03T07:55:43.521084Z","iopub.status.idle":"2023-04-03T07:55:43.531660Z","shell.execute_reply.started":"2023-04-03T07:55:43.521030Z","shell.execute_reply":"2023-04-03T07:55:43.529937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds), True # 반환값","metadata":{"execution":{"iopub.status.busy":"2023-04-03T07:55:52.164697Z","iopub.execute_input":"2023-04-03T07:55:52.165134Z","iopub.status.idle":"2023-04-03T07:55:52.170945Z","shell.execute_reply.started":"2023-04-03T07:55:52.165092Z","shell.execute_reply":"2023-04-03T07:55:52.169872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-3. 모델 훈련 및 성능 검증\n\n### 3-3-1. OOF 예측 방식\n\n- **OOF 예측 (Out of Fold prediction)**: K 폴드 교차 검증을 수행하면서 각 폴드마다 테스트 데이터로 예측하는 방식\n    - K 폴드 교차 검증을 하면서 폴드마다\n    1. 훈련 데이터로 모델을 훈련\n    2. 검증 데이터로 모델 성능을 측정\n    3. 테스트 데이터로 최종 타깃 확률도 예측\n    \n    \n- **OOF 예측 절차**\n    1. 전체 훈련 데이터를 K개 그룹으로 나눈다\n    2. K개 그룹 중 한 그룹은 검증 데이터, 나머지 K-1개 그룹은 훈련 데이터로 지정\n    3. 훈련 데이터로 모델을 훈련\n    4. 훈련된 모델을 이용해 검증 데이터로 타깃 확률을 예측, 전체 테스트 데이터로도 타깃 확률을 예측\n    5. 검증 데이터로 구한 예측 확률과 테스트 데이터로 구한 예측 확률을 기록\n    6. 검증 데이터를 다른 그룹으로 바꿔가며 2~5번 전차를 총 K번 반복\n    7. K개 그룹의 검증 데이터로 예측한 확률을 훈련 데이터 실제 타깃값과 비교해 성능 평가 점수를 계산. \n        - 이 점수로 모델 성능을 가늠\n    8. 테스트 데이터로 구한 K개 예측 확률의 평균을 구한다. 이 값이 최종 예측 확률이며, 제출해야하는 값\n\n\n- **OOF 예측 방식의 장점**\n    1. 과대적합 방지 효과\n    2. 앙상블 효과가 있어 모델 성능이 좋아짐\n        - 단일 모델로 한 번만 예측하는 것이 아니라, K개 모델로 K번 예측해 평균을 하므로\n\n\n### 3-3-2. OOF 방식으로 LightGBM 훈련\n\n- 이제 베이스라인 모델, LightGBM,을 훈련하면서 OOF 예측도 실제로 해보자\n\n\n- 먼저, 층화 K 폴드 교차 검증기를 생성\n    - 타깃값이 불균형하므로 \"K폴드\" 보다는 \"층화K폴드\"가 좋음","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\n# 층화 K 폴드 교차 검증기\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T08:13:32.068115Z","iopub.execute_input":"2023-04-03T08:13:32.068511Z","iopub.status.idle":"2023-04-03T08:13:32.149467Z","shell.execute_reply.started":"2023-04-03T08:13:32.068473Z","shell.execute_reply":"2023-04-03T08:13:32.148359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'objective': 'binary',\n          'learning_rate': 0.01,\n          'force_row_wise': True, #경고문을 없애려고 추가한 파라미터\n          'random_state': 0}","metadata":{"execution":{"iopub.status.busy":"2023-04-03T08:14:25.400430Z","iopub.execute_input":"2023-04-03T08:14:25.400839Z","iopub.status.idle":"2023-04-03T08:14:25.406300Z","shell.execute_reply.started":"2023-04-03T08:14:25.400803Z","shell.execute_reply":"2023-04-03T08:14:25.405005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0]) \n# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0]) ","metadata":{"execution":{"iopub.status.busy":"2023-04-03T08:15:13.531829Z","iopub.execute_input":"2023-04-03T08:15:13.532331Z","iopub.status.idle":"2023-04-03T08:15:13.539698Z","shell.execute_reply.started":"2023-04-03T08:15:13.532293Z","shell.execute_reply":"2023-04-03T08:15:13.537942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\n\n# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    # 각 폴드를 구분하는 문구 출력\n    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n    \n    # 훈련용 데이터, 검증용 데이터 설정 \n    X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n    X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n\n    # LightGBM 전용 데이터셋 생성 \n    dtrain = lgb.Dataset(X_train, y_train) # LightGBM 전용 훈련 데이터셋\n    dvalid = lgb.Dataset(X_valid, y_valid) # LightGBM 전용 검증 데이터셋\n\n    # LightGBM 모델 훈련 \n    lgb_model = lgb.train(params=params,        # 훈련용 하이퍼파라미터\n                          train_set=dtrain,     # 훈련 데이터셋\n                          num_boost_round=1000, # 부스팅 반복 횟수\n                          valid_sets=dvalid,    # 성능 평가용 검증 데이터셋\n                          feval=gini,           # 검증용 평가지표\n                          early_stopping_rounds=100, # 조기종료 조건\n                          verbose_eval=100)     # 100번째마다 점수 출력\n    \n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n    \n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n    \n    # 검증 데이터 예측 확률에 대한 정규화 지니계수 \n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T08:15:51.761481Z","iopub.execute_input":"2023-04-03T08:15:51.761884Z","iopub.status.idle":"2023-04-03T08:21:50.853618Z","shell.execute_reply.started":"2023-04-03T08:15:51.761848Z","shell.execute_reply":"2023-04-03T08:21:50.852189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T08:21:50.856355Z","iopub.execute_input":"2023-04-03T08:21:50.856851Z","iopub.status.idle":"2023-04-03T08:21:53.090045Z","shell.execute_reply.started":"2023-04-03T08:21:50.856787Z","shell.execute_reply":"2023-04-03T08:21:53.085897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}